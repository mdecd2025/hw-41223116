var tipuesearch = {"pages": [{'title': 'About', 'text': '課程名稱：協同產品設計實習 - Collaborative Product Design Practice \n', 'tags': '', 'url': 'About.html'}, {'title': 'w1', 'text': '學員作業網站:\xa0 https://mdecd2025.github.io/hw-41223116/ \n 學員作業倉儲:\xa0 https://github.com/mdecd2025/hw-41223116 \n 團隊(2)作業網站: https://mdecd2025.github.io/2a-ag2/ \n 團隊(2)作業倉儲: https://github.com/orgs/mdecd2025/teams/ag2/members \n \n 課程代號: cd2025 \n Teams 線上教學: \n 以 "學號@nfu.edu.tw" 登入 \xa0 https://login.microsoftonline.com/ \xa0 Office 365 \n Teams 團隊代碼:\xa0 p5z4eku \n \n 課程評分: \n Homework (30%) - 每週至少提交兩次與課程進度有關的內容, 完成後填回自評表單 \n Exam (40%) - 建立包含操作流程影片、心得以及提供檔案下載的網頁後填回自評表單 \n Final Report (30%) - 利用網頁內容進行簡報並提交 pdf 格式書面報告, 完成後填回自評表單 \n \n', 'tags': '', 'url': 'w1.html'}, {'title': 'w16', 'text': 'webots檔案 /downloads/w16..7z \n \n', 'tags': '', 'url': 'w16.html'}, {'title': 'task5', 'text': '\n 請整理 \xa0 https://cyberbotics.com/doc/guide/introduction-to-webots \xa0 中重要的英文單字與用法, 並且針對其中所使用的英文文法逐句說明.\n', 'tags': '', 'url': 'task5.html'}, {'title': 'Important Vocabulary and Phrases (重要詞彙與短語)', 'text': '\n Simulation \xa0 - 模擬：一個模仿現實世界過程或系統的過程。 \n Prototyping \xa0 - 原型製作：創建產品或系統的早期版本（原型）的過程。 \n Mobile Robot \xa0 - 移動機器人：能夠在其環境中移動的機器人，通常配有感測器和驅動器。 \n Locomotion Schemes \xa0 - 移動方式：機器人移動的方式或系統（例如，輪式機器人、步態機器人、飛行機器人等）。 \n Sensors \xa0 - 感測器：用來檢測並對物理刺激作出反應的裝置，例如相機或距離感測器。 \n Actuators \xa0 - 驅動器：執行動作的裝置，如馬達或車輪。 \n Controller Program \xa0 - 控制程式：控制機器人行為或運作的程式。 \n Interface \xa0 - 介面：系統之間的連接或溝通（在此指模擬機器人與實體機器人之間的介面）。 \n Multi-Agent Research \xa0 - 多代理研究：涉及多個機器人共同工作的研究，通常是協作或集群設定。 \n Adaptive Behavior \xa0 - 自適應行為：基於環境或經驗變化的行為（通常涉及如神經網絡等人工智慧方法）。 \n BotStudio \xa0 - BotStudio：一種簡單的圖形化程式設計語言，用於在Webots中編程機器人。 \n VRML97 (Virtual Reality Modeling Language) \xa0 - VRML97（虛擬現實建模語言）：描述3D物體和環境的標準。 \n PROTOTYPE Files \xa0 - PROTOTYPE檔案：定義模擬中新增物件的檔案。 \n World File \xa0 - 世界檔案：定義模擬中環境、物體和機器人的檔案。 \n Controller Directory \xa0 - 控制器目錄：儲存機器人控制程式源碼和二進位檔案的目錄。 \n Supervisor Controller \xa0 - 監督控制器：一種特殊的控制器，具有更高的許可權來管理模擬功能。 \n Binary Executables \xa0 - 二進位執行檔：已編譯並可在系統中運行的程式檔案（例如".exe"檔案）。 \n Interpretation vs. Compilation \xa0 - 解釋與編譯：指編程語言的處理方式（例如，編譯語言如C/C++與解釋語言如Python的區別）。\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \n \n', 'tags': '', 'url': 'Important Vocabulary and Phrases (重要詞彙與短語).html'}, {'title': '請列出上述文章中的重要的英文單字與解釋, 以及出現在文句中的用法', 'text': '\n Grammar Explanation (文法說明) \n Sentence 1: \n "Webots is a professional mobile robot simulation software package." \n \n \n "Webots" \xa0 (主語) \xa0 is \xa0 (連繫動詞) \xa0 a professional mobile robot simulation software package \xa0 (謂語名詞短語)。這是一個簡單的陳述句，描述Webots是什麼。 \n \n \n Sentence 2: \n "It offers a rapid prototyping environment, that allows the user to create 3D virtual worlds with physics properties such as mass, joints, friction coefficients, etc." \n \n \n "It offers" \xa0 (主語 + 動詞) 介紹了Webots的功能。 \n "that allows" \xa0 是一個關係子句，修飾 "environment"，解釋環境的功能。 \n "the user to create" （不定式短語）說明用戶可以進行的操作。 \n "with physics properties such as mass, joints, friction coefficients, etc." \xa0 提供有關虛擬世界的物理屬性的詳細信息。 \n \n \n Sentence 3: \n "The user can add simple passive objects or active objects called mobile robots." \n \n \n "The user can add" （主語 + 情態動詞 + 動詞原形）表示用戶可以進行的操作或許可。 \n "called mobile robots" \xa0 是一個現在分詞短語，修飾 "active objects"，提供額外信息。 \n \n \n Sentence 4: \n "These robots can have different locomotion schemes (wheeled robots, legged robots, or flying robots)." \n \n \n "can" \xa0 表示能力或可能性。 \n "different locomotion schemes" \xa0 表示機器人可以採用的不同移動方式。 \n \n \n Sentence 5: \n "Moreover, they may be equipped with a number of sensor and actuator devices, such as distance sensors, drive wheels, cameras, motors, touch sensors, emitters, receivers, etc." \n \n \n "may be equipped" \xa0 使用情態動詞 \xa0 may \xa0 表示可能性。 \n "such as" \xa0 用來介紹感測器和驅動器裝置的例子。 \n \n \n Sentence 6: \n "Finally, the user can program each robot individually to exhibit the desired behavior." \n \n \n "The user can program" \xa0 顯示了用戶的能力或許可。 \n "to exhibit" \xa0 是不定式動詞，說明編程的目的是為了表現所需的行為。 \n \n \n Sentence 7: \n "Webots also contains a number of interfaces to real mobile robots, so that once your simulated robot behaves as expected, you can transfer its control program to a real robot like e-puck, DARwIn-OP, Nao, etc." \n \n \n "so that" \xa0 引導目的子句，解釋為何要轉移控制程式。 \n "once your simulated robot behaves" \xa0 是時間條件子句，表示模擬機器人表現正常後，才會進行轉移。 \n \n \n Sentence 8: \n "What can I do with Webots?" \n \n \n 這是一個簡單的疑問句，使用情態動詞 \xa0 "can" \xa0 問Webots的功能。 \n \n \n Sentence 9: \n "Webots is well suited for research and educational projects related to mobile robotics." \n \n \n "is well suited for" \xa0 表示Webots適合於某些用途。 \n "related to mobile robotics" \xa0 描述了Webots所支持的研究領域。 \n \n \n Sentence 10: \n "Many mobile robotics projects have relied on Webots for years in the following areas:" \n \n \n "have relied" \xa0 使用現在完成時，表示一個持續或反覆發生的動作。 \n 這句話列出了Webots被使用的領域。 \n \n \n Sentence 11: \n "What do I need to know to use Webots?" \n \n \n 這是另一個疑問句，使用 \xa0 "do I need to know" \xa0 來詢問需要掌握的知識。 \n \n \n Sentence 12: \n "You will need a minimal amount of technical knowledge to develop your own simulations." \n \n \n "You will need" （將來時）表示必須具備的條件或需求。 \n "a minimal amount of technical knowledge" \xa0 指出所需的知識。 \n \n \n Sentence 13: \n "If you don\'t want to use existing robot models provided within Webots and would like to create your own robot models, or add special objects in the simulated environments, you will need a basic knowledge of 3D computer graphics and VRML97 description language." \n \n \n "If you don\'t want" （條件句）提出一種情境，表示若不使用現有的模型。 \n "would like to create" \xa0 表示替代的期望或行動。 \n "you will need" （將來時）強調執行某些操作所需的知識。 \n \n \n Sentence 14: \n "How do I get User Support?" \n \n \n 這是簡單的疑問句，詢問如何獲得使用者支持。 \n \n \n \n Overall Grammar Features (整體文法特點) \n \n \n Present Simple Tense (現在簡單時) : 用來描述事實或一般性資訊（例如："Webots is..."）。 \n Modal Verbs (情態動詞)（can, may, would） : 表示可能性、能力或請求（例如："You can program..."）。 \n Relative Clauses (關係子句) : 提供名詞的額外資訊（例如："robots called mobile robots"）。 \n Future Tense (將來時) : 描述將來會發生的動作（例如："You will need..."）。 \n Conditional Clauses (條件句) : 描述假設的情況及其結果（例如："If you don\'t want..."） \n \n', 'tags': '', 'url': '請列出上述文章中的重要的英文單字與解釋, 以及出現在文句中的用法.html'}, {'title': 'Homework', 'text': '作業 (30%) \n HW1 (5%):  建立由 Box 組成的平面四連桿機構 Webots 模擬場景 \n part1: \n 請各學員在 USB 隨身碟或個人電腦上完成 cd2025 課程所需的可攜系統配置: \n 下載  portable_wcm2025.7z  (330MB, 解開壓縮後 1.4GB) \n Webots_2025a.7z  (1.5 GB, 解開後約為 2.9GB, 可單獨運作) \n Webots_2025a_web.7z  (171 MB, 解開壓縮後約為 1GB, 必須連網運作) \n Blender4.2.7z \n part2: \n 請各學員完成可攜程式系統配置後, 利用 Webots R2025a 中寬度與高度都為 0.1m 的 box 物件建立一個簡單的平面四連桿機構模擬場景. \n base (基座) 長度 1m, link1 長度 0.4m, link2 長度 0.6m, link3 長度 0.9m, 各轉軸均為 HingeJoint, joint1 旋轉速度設定為 1radian/sec. \n part3: \n 模擬場景啟動後, 按下 s 鍵機構開始作動, 按下 p 鍵後機構暫停. \n 參考資料: \n cd2025_hw1_demo.7z \n HW2 (5%):  建立由 CAD 繪製零件組成的平面四連桿機構 Webots 模擬場景 \n 各學員請利用 CAD 系統依據 HW1 的連桿尺寸與運動方式, 配置適當大小的旋轉軸以及基座後, 利用 Webots R2025a 完成一個簡單的平面四連桿機構模擬場景. \n 參考資料: \n fourbar_slvs.7z \n HW3 (20%): 建立 Webots 桌上籃球遊戲機模擬系統 \n 請各分組利用CAD 系統建立一個能在電腦桌 (1600W X 700D X 740H mm) 上運作的投籃機構 ( 參考影片 )後, 導入 Webots R2025a 套件, 建立一個能由使用者透過鍵盤按鍵操作, 且具備計分板的籃球遊戲機模擬系統. \n 參考資料: \n 參考資料: \n fourbar_ball_throwing_linkage.slvs \n sixbar_ball_throwing_linkage.slvs \n \n HW 1 (5%):  建立由 Box 組成的平面四連桿機構 Webots 模擬場景 \n 操作影片標題：國立虎尾科技大學 - 機械設計工程系 - cd2025 HW1 - 學員學號 \n HW2 (5%):  建立由 CAD 繪製零件組成的平面四連桿機構 Webots 模擬場景 \n 操作影片標題: 國立虎尾科技大學 - 機械設計工程系 - cd2025 HW2 - 學員學號 \n HW3 (20%): 建立 Webots 桌上籃球遊戲機模擬系統 \n 操作影片標題: 國立虎尾科技大學 - 機械設計工程系 - cd2025 HW3 - 學員學號 \n \n HW1 相關提問: \n Webots 是什麼樣的軟體？它主要用途為何？ \n Webots 是一套由  Cyberbotics  所開發的  開源 3D 機器人模擬軟體 ，用於模擬機器人在真實世界中行為的虛擬環境。其主要用途包括： \n \n \n 設計與模擬移動式或靜態機器人系統 \n \n \n 測試機器人控制演算法（例如感測器融合、路徑規劃、強化學習等） \n \n \n 教學與研究（機器人學、人工智慧、自主導航等） \n \n \n 開發與驗證機器人軟硬體設計（可搭配真實機器人） \n \n \n', 'tags': '', 'url': 'Homework.html'}, {'title': '如何在 Webots 中建立並執行一個新的模擬世界（world）？', 'text': '\n \n \n 啟動 Webots 。 \n \n \n 選單中點選  File  →  New World  建立新的模擬場景。 \n \n \n 可透過左側「場景樹」(Scene Tree) 加入環境物件與機器人，例如： \n \n \n 加入地面： Add > Solid > Floor \n \n \n 加入機器人： Add > Robot \n \n \n \n \n 編輯物件屬性，如大小、材質、位置等。 \n \n \n 儲存世界檔案（副檔名為  .wbt ）。 \n \n \n 點選「播放」按鈕（上方工具列 ▶️），即可執行模擬。 \n \n \n \n', 'tags': '', 'url': '如何在 Webots 中建立並執行一個新的模擬世界（world）？.html'}, {'title': '請簡述 Webots 控制器（controller）的功能及其與機器人的關係。', 'text': '\n \n \n 控制器 是 Webots 中操控機器人行為的程式碼（通常是 C、Python、C++ 等語言撰寫）。 \n \n \n 它直接與機器人的感測器與致動器互動（例如讀取紅外線感測器、控制馬達轉速）。 \n \n \n 每個控制器程式通常對應一個機器人，可在  robot  物件的  controller  欄位指定對應的控制器名稱。 \n \n \n 控制器執行週期性迴圈（如  while robot.step(timestep) != -1: ）來模擬真實時間控制。 \n \n \n \n', 'tags': '', 'url': '請簡述 Webots 控制器（controller）的功能及其與機器人的關係。.html'}, {'title': 'Webots 中的 "Supervisor" 是什麼？它與一般機器人控制器有何不同？', 'text': '\n \n \n Supervisor  是一種特殊的控制器，擁有  更高層次的控制權限 。 \n \n \n 除了能像一般控制器一樣控制機器人，它還能： \n \n \n 修改場景中的物件（新增、刪除、移動） \n \n \n 取得所有物件的位置與狀態 \n \n \n 重設模擬、儲存世界狀態、載入新的世界 \n \n \n 用於強化學習（如重置環境） \n \n \n \n \n 適用於： 全局管理、多機器人系統、評分系統、自動測試場景等應用 \n \n \n \n', 'tags': '', 'url': 'Webots 中的 "Supervisor" 是什麼？它與一般機器人控制器有何不同？.html'}, {'title': '如何將 Webots 世界（world）或機器人設定檔分享給他人，確保對方可順利開啟模擬', 'text': '\n \n 其他依賴檔案（貼圖、模型、資料檔） \n \n \n worlds/ ：模擬場景檔（ .wbt ） \n \n \n protos/ ：自訂機器人或物件的描述檔（ .proto ） \n \n \n controllers/ ：控制器程式碼（每個控制器一個子資料夾） \n \n \n 其他依賴檔案（貼圖、模型、資料檔） \n \n \n 打包方式： \n \n \n 使用 \xa0 .zip \xa0 或 \xa0 .tar.gz \xa0 壓縮整個專案資料夾。 \n \n \n 確保分享者與接收者都安裝有相同版本的 Webots。 \n \n \n 接收者只需解壓縮後，透過 Webots 開啟 \xa0 .wbt \xa0 檔即可。 \n \n \n \n \n', 'tags': '', 'url': '如何將 Webots 世界（world）或機器人設定檔分享給他人，確保對方可順利開啟模擬.html'}, {'title': 'Webots 支援哪些主流程控制語言？各有何優缺點？', 'text': '\n \n \n 語言 \n 優點 \n 缺點 \n \n \n \n \n C/C++ \n 高效能，資源控制佳，適合嵌入式模擬與真實硬體整合 \n 開發速度慢、語法較繁瑣 \n \n \n Python \n 撰寫快速、易讀、資源豐富（支援 NumPy、PyTorch） \n 效能略低，不適合重度運算 \n \n \n Java \n 跨平台佳，結構清晰 \n 程式碼稍長、社群支援較少 \n \n \n MATLAB \n 適合科學計算與控制理論模擬 \n 授權成本高，與 Webots 整合需額外安裝套件 \n \n \n \n', 'tags': '', 'url': 'Webots 支援哪些主流程控制語言？各有何優缺點？.html'}, {'title': '請說明如何使用 Webots 的 Console 與 Debug 工具協助程式錯誤排除。', 'text': '\n \n Console （控制器輸出視窗）： \n \n \n 顯示控制器 \xa0 print() \xa0 或 \xa0 printf() \xa0 的輸出。 \n \n \n 顯示錯誤訊息、例外（Exception）與除錯訊息。 \n \n \n 可使用 \xa0 robot.getName() \xa0 等方法輸出除錯資訊。 \n \n \n \n \n Debug 工具 （在 IDE 或外部開發工具中）： \n \n \n 可將控制器連結至外部 IDE（如 Visual Studio Code）來設斷點除錯。 \n \n \n C/C++ 控制器可透過 gdb 除錯。 \n \n \n Python 控制器可加入 \xa0 import pdb; pdb.set_trace() \xa0 進入互動除錯模式。 \n \n \n \n Supervisor 支援除錯 ：\n \n \n 可檢查世界中的物件狀態與位置變化。 \n \n \n 可設定模擬暫停、單步執行等功能。 \n \n \n \n \n \n \n', 'tags': '', 'url': '請說明如何使用 Webots 的 Console 與 Debug 工具協助程式錯誤排除。.html'}, {'title': 'Tutorial3 相關提問:', 'text': '1.  如何讓機器人偵測地面顏色？ \n 在 Webots 中，使用地面感測器（ Ground Sensors ）來偵測地面顏色或反射率。這些感測器通常裝設在機器人底部，透過模擬的光學反射值來讀取不同顏色的地面資訊。 \n \n 2.  Ground Sensors 在 Webots 裡的作用為何？ \n Ground Sensors 模擬了現實中的  反射光感測器 ，其作用為： \n \n \n 偵測地面表面顏色（如黑、白、灰） \n \n \n 協助機器人辨認路線（如循線行走） \n \n \n 用於場地區辨（例如偵測進入特定區域） \n \n \n 這些感測器會回傳浮點數值，代表地面反光程度。 \n \n 3.  如何在程式中取得 Ground Sensor 的數值？ \n 以  Python 為例 ： \n \n python \n \n \n \n \n \n ground_sensor = robot.getDevice(\'gs0\') # 取得地面感測器裝置 ground_sensor.enable(timestep) # 啟用感測器，設定取樣週期 while robot.step(timestep) != -1:  value = ground_sensor.getValue() # 讀取感測器數值  print("Ground sensor value:", value) \n \n \n 注意：常見 e-puck 使用三個地面感測器： gs0 ,  gs1 ,  gs2 ，分別對應左、中、右。 \n \n \n 4.  Tutorial3 中的 e-puck 機器人如何根據地面顏色改變行為？ \n 在 Webots 的 Tutorial 3 中： \n \n \n e-puck 機器人使用  三個 ground sensors \n \n \n 程式會判斷讀到的地面亮度： \n \n \n 當中間感測器 ( gs1 ) 偵測到低亮度（黑線），機器人會  轉向或停止 \n \n \n 若感測值為高亮度（白地），繼續直行 \n \n \n \n \n 範例邏輯： \n \n python \n \n \n \n middle_value = gs1.getValue() if middle_value < threshold: # 低亮度 = 黑線  turn_left() else:  move_forward() \n \n \n \n \n 5.  為什麼要對 Ground Sensor 的數值進行校正（calibration）？ \n 校正目的： \n \n \n 每種地面材質、光照條件或貼圖會影響感測器回傳數值。 \n \n \n 相同的黑色/白色在不同模擬場景中可能對應不同數值。 \n \n \n 校正能確保感測值範圍穩定，例如： \n \n \n 白地：約 1000（高反射） \n \n \n 黑線：約 300（低反射） \n \n \n \n \n 方法 ：可透過顯示感測器數值（ print() ）實際量測並設定適當的閾值（threshold）。 \n \n 6.  如何設定 Ground Sensor 的 sampling period？ \n 可透過  enable(timestep)  設定每幾毫秒更新一次感測器數值： \n \n python \n \n \n \n timestep = int(robot.getBasicTimeStep()) ground_sensor.enable(timestep) # 每個模擬 step 更新一次數值 \n \n \n \n timestep =  int (robot.getBasicTimeStep()) ground_sensor.enable(timestep)  # 每個模擬 step 更新一次數值   \n \n \n 7.  e-puck 機器人可以偵測哪些顏色？如何判斷？ \n Ground Sensors  無法辨別真實色彩（RGB） ，只能量測「反射強度（亮度）」。 \n \n \n 可偵測「明暗差異」，例如： \n \n \n 黑（低反射）：數值低 \n \n \n 白（高反射）：數值高 \n \n \n 灰：介於兩者之間 \n \n \n \n \n 若需判斷具體顏色（如紅、綠、藍），需使用  Camera + 色彩分析 。 \n \n \n \n 8.  Tutorial3 如何讓 e-puck 在遇到黑線時做出反應？ \n 主要邏輯如下： \n \n \n 透過中央感測器讀取地面亮度。 \n \n \n 當亮度值低於設定門檻（即為黑線），改變輪子速度使機器人轉向或後退。 \n \n \n 否則繼續前進。 \n \n \n \n \n \n 9.  若地面顏色偵測判斷有誤，可能原因有哪些？ \n 可能原因如下： \n \n \n 閾值設定錯誤 ：未正確校正不同表面材質下的感測數值 \n \n \n 貼圖問題 ：地面材質或顏色不明顯，導致感測值變異不大 \n \n \n 感測器啟用錯誤 ：未設定 sampling period 或未啟用感測器 \n \n \n 程式邏輯錯誤 ：誤判或使用錯誤的感測器（如使用  gs2  卻以為是中央） \n \n \n 模擬步長過長 ：感測器更新頻率太低，錯過偵測時機 \n \n \n', 'tags': '', 'url': 'Tutorial3 相關提問:.html'}, {'title': 'Tutorial4 相關提問:', 'text': '1.  如何讓機器人偵測牆壁或障礙物？ \n 可使用 Webots 中的  距離感測器（DistanceSensor）  來達成。e-puck 機器人預設裝有  8 個紅外線距離感測器 （名為  ps0 ~ ps7 ），可用來偵測牆壁、物體或障礙物的距離。 \n 這些感測器通常分佈於機器人四周，涵蓋前、側、後方。 \n \n 2.  Webots 的距離感測器（DistanceSensor）如何運作？ \n \n \n 模擬的是 紅外線反射感測器 。 \n \n \n 根據物體與感測器之間的距離與材質反射特性，回傳一個 模擬的數值 。 \n \n \n 數值愈高，代表物體距離愈近；數值愈低，代表前方空曠。 \n \n \n \n 注意：不同物體、角度、顏色會影響感測精度。 \n \n \n 3.  如何在程式中啟用並讀取 DistanceSensor 的數值？ \n Python 範例： \n \n python \n \n \n sensors = [] for i in range(8):  sensor = robot.getDevice(f\'ps{i}\')  sensor.enable(timestep)  sensors.append(sensor) while robot.step(timestep) != -1:  values = [s.getValue() for s in sensors]  print("Sensor readings:", values) \n \n \n \n \n \n 4.  Tutorial4 中，e-puck 機器人如何實作避障行為？ \n 基本策略： \n \n \n 偵測左右兩側感測器的數值（如  ps0~ps2  為右側， ps5~ps7  為左側）。 \n \n \n 若右側感測值高（表示障礙靠右），機器人向左轉。 \n \n \n 若左側感測值高，則向右轉。 \n \n \n 若無障礙，則直行。 \n \n \n 簡化邏輯（Python）如下： \n \n python \n \n \n \n left = max(ps5.getValue(), ps6.getValue(), ps7.getValue()) right = max(ps0.getValue(), ps1.getValue(), ps2.getValue()) if left > 80.0:  turn_right() elif right > 80.0:  turn_left() else:  move_forward() \n \n \n \n \n 5.  距離感測器數值的單位是什麼？如何轉換？ \n \n \n Webots 的  DistanceSensor.getValue()  回傳的是一個 模擬的原始值 ， 不是公尺或公分 。 \n \n \n 數值範圍依感測器與模擬物件不同而異，一般 e-puck 紅外線感測器範圍約  0 到 1000 左右 。 \n \n \n 若要轉為物理距離（例如公分），需要 實測校正曲線 或查閱原型感測器（如 e-puck 使用的 Sharp IR sensor）來建構換算關係。 \n \n \n \n 6.  如何設定距離感測器的 sampling period？ \n 與其他感測器相同，使用  enable(timestep)  來設定感測更新頻率。 \n \n python \n \n \n \n \n \n timestep = int(robot.getBasicTimeStep()) ps0.enable(timestep) \n \n \n 7.  當機器人同時偵測到左、右兩側有障礙物時，應如何設計行為？ \n 策略建議： \n \n \n 停下來後退 ，再隨機選擇方向轉彎（避免陷入障礙中間）。 \n \n \n 使用中央感測器（如  ps3 ,  ps4 ）判斷前方距離是否仍可通行。 \n \n \n 加入「優先方向」或「轉向權重」邏輯，例如偏向上次未轉的方向。 \n \n \n 範例： \n \n python \n \n \n \n if left > 80 and right > 80:  move_backward()  if random() > 0.5:  turn_left()  else:  turn_right() \n \n \n \n \n \n 8.  為什麼避障時要考慮多個感測器的數值？ \n 原因如下： \n \n \n 障礙物形狀與方向多變，單一感測器可能無法偵測完整資訊。 \n \n \n 可避免誤判（如側面偵測不到但仍有障礙）。 \n \n \n 提高判斷精度，例如左右多個感測器數值加總、取最大值等。 \n \n \n 多感測器可提供 方向性 資訊（如障礙靠前左或後左）。 \n \n \n \n 9.  Tutorial4 若機器人無法正確避障，可能的解決方法有哪些？ \n 可能原因與對應解法： \n \n \n \n \n \n 問題 \n 解決方法 \n \n \n \n \n 感測器未啟用 \n 檢查程式是否  enable()  感測器 \n \n \n 閾值設錯 \n 實測感測器讀數並調整閾值 \n \n \n 障礙物太遠 \n 降低偵測觸發門檻（例如從 >100 改為 >80） \n \n \n 判斷邏輯錯誤 \n 檢查左右邏輯是否顛倒 \n \n \n 避障反應延遲 \n 增加 sampling 頻率，減少步長 \n \n \n 模型遮擋感測器 \n 檢查感測器位置是否被模型本體或其他物件擋住 \n \n \n 動作太慢 \n 加快轉彎速度或改變轉彎策略 \n \n \n \n \n', 'tags': '', 'url': 'Tutorial4 相關提問:.html'}, {'title': 'Tutorial5 相關提問:', 'text': '', 'tags': '', 'url': 'Tutorial5 相關提問:.html'}, {'title': '如何讓機器人依照不同地面顏色或障礙物狀態做出不同反應？', 'text': '策略：\n 結合地面感測器（Ground Sensor）與距離感測器（Distance Sensor）判斷環境，再做出對應反應。 \n範例邏輯：\n \n python \n \n ground = gs1.getValue() left_obstacle = ps7.getValue() right_obstacle = ps0.getValue() if ground < 500: # 黑線  stop() elif left_obstacle > 80 or right_obstacle > 80: # 有障礙物  avoid_obstacle() else:  move_forward() \n \n \n \n \n \n \n \n', 'tags': '', 'url': '如何讓機器人依照不同地面顏色或障礙物狀態做出不同反應？.html'}, {'title': '二、Tutorial 5 中如何結合多種感測器進行複雜任務？', 'text': 'Tutorial5 示範了如何利用： \n \n \n 地面感測器 （循線、辨識區域） \n \n \n 距離感測器 （避障） \n \n \n 有限狀態機 （控制任務流程） \n \n \n', 'tags': '', 'url': '二、Tutorial 5 中如何結合多種感測器進行複雜任務？.html'}, {'title': '應用：', 'text': '機器人能同時 巡線 → 遇障 → 閃避 → 回歸巡線 → 完成任務 。 \n \n', 'tags': '', 'url': '應用：.html'}, {'title': '三、如何設計機器人巡線並同時避障？', 'text': '這是典型的 多任務整合問題 ，可採用 優先權決策或狀態機（FSM）實作 。 \n', 'tags': '', 'url': '三、如何設計機器人巡線並同時避障？.html'}, {'title': '常見策略：', 'text': '\n \n 高優先權任務優先處理 （如避障 > 巡線） \n \n \n 巡線：根據  gs1  為中心調整方向 \n \n \n 若  ps0~ps2  或  ps5~ps7  偵測到障礙物則進入避障模式 \n \n \n \n', 'tags': '', 'url': '常見策略：.html'}, {'title': '四、若多種感測器回報衝突訊息，程式該如何決策？', 'text': '建議使用  優先權架構或狀態機處理 ： \n \n \n 避障為高優先 → 地面為中優先 → 其他行為為低優先 \n \n \n 也可使用  感測器融合機制加權平均  或  決策表 \n \n \n', 'tags': '', 'url': '四、若多種感測器回報衝突訊息，程式該如何決策？.html'}, {'title': '範例邏輯：', 'text': '\n python \n \n \n \n if obstacle_detected:  enter_avoid_mode() elif line_detected:  follow_line() else:  search_line() \n \n \n \n \n \n', 'tags': '', 'url': '範例邏輯：.html'}, {'title': '五、在 Tutorial5 裡，機器人如何完成任務流程的狀態切換？', 'text': '透過**有限狀態機（FSM）**來處理： \n \n \n 定義狀態（如：IDLE, FOLLOW_LINE, AVOID, END） \n \n \n 根據感測器輸入決定狀態轉移 \n \n \n範例結構：\n \n python \n \n \n \n state = "FOLLOW_LINE" if state == "FOLLOW_LINE":  if obstacle_detected:  state = "AVOID"  else:  follow_line() elif state == "AVOID":  if obstacle_cleared:  state = "FOLLOW_LINE"  else:  avoid_obstacle() \n \n \n \n \n \n \n', 'tags': '', 'url': '五、在 Tutorial5 裡，機器人如何完成任務流程的狀態切換？.html'}, {'title': '六、如何在程式中設計有限狀態機（FSM）？', 'text': '設計步驟：\n \n \n 定義狀態集 ：列出所有行為狀態（如：IDLE、巡線、避障、完成） \n \n \n 建立轉移邏輯 ：設定感測條件與狀態間的轉移關係 \n \n \n 用變數管理狀態 ：例如  state = "LINE_FOLLOW" \n \n \n 在主迴圈中處理行為與轉移 \n \n \n \n', 'tags': '', 'url': '六、如何在程式中設計有限狀態機（FSM）？.html'}, {'title': '七、Tutorial5 的挑戰題目有哪些？如何著手解決？', 'text': '常見挑戰：\n \n \n 在黑線中穿越障礙並返回路徑 \n \n \n 抵達指定顏色區域後停下或發出訊號 \n \n \n 通過不同顏色地面改變行為（例如紅色區轉彎、藍色區掉頭） \n \n \n解法建議：\n \n \n 使用地面感測器判斷顏色區域 \n \n \n 使用狀態機進行行為轉換 \n \n \n 加入路徑紀錄或尋徑策略協助回到原始路線 \n \n \n \n', 'tags': '', 'url': '七、Tutorial5 的挑戰題目有哪些？如何著手解決？.html'}, {'title': '八、若要讓機器人自主完成一個完整路徑的巡邏任務，應加入哪些功能？', 'text': '必要功能：\n \n \n 路線循跡（巡線） \n \n \n 障礙物偵測與避障 \n \n \n 區域辨識與轉向控制 \n \n \n 狀態管理（FSM） \n \n \n 導航記憶（若需回到原點或重覆路徑） \n \n \n （進階） 路線地圖構建、SLAM、里程計 \n \n \n \n', 'tags': '', 'url': '八、若要讓機器人自主完成一個完整路徑的巡邏任務，應加入哪些功能？.html'}, {'title': '九、綜合 Tutorial3~5，請說明感測器資料融合（Sensor Fusion）的意義與應用', 'text': '意義：\n 感測器資料融合（Sensor Fusion） 指的是將來自 不同感測器 的輸入資訊整合，用以做出更 穩定、準確、完整的判斷 。 \n在 Tutorial3~5 中的應用：\n \n \n \n \n \n 感測器 \n 功能 \n 資料融合應用 \n \n \n \n \n Ground Sensor \n 判斷地面顏色/亮度 \n 區域偵測、巡線 \n \n \n DistanceSensor \n 偵測障礙物距離 \n 避障、判斷前方通行性 \n \n \n 狀態機 \n 管理多重任務流程 \n 整合感測資訊 → 決策狀態切換 \n \n \n \n \n \n 優點： \n \n \n \n \n \n 減少單一感測器誤判 \n \n \n 提升環境理解與機器人自主性 \n \n \n 可實作複合任務（巡線 + 避障 + 任務完成） \n \n \n', 'tags': '', 'url': '九、綜合 Tutorial3~5，請說明感測器資料融合（Sensor Fusion）的意義與應用.html'}, {'title': 'Tutorial6 相關提問:', 'text': '一、 如何在 Webots 中使用攝影機（Camera）？ \n Webots 提供的  Camera 裝置  可模擬真實機器人的相機模組，允許擷取即時畫面，用於： \n \n \n 顏色辨識（如偵測紅色物體） \n \n \n 影像處理（圖形辨識、QR code） \n \n \n 電腦視覺應用（如 OpenCV、物件追蹤） \n \n \n \n 二、 Camera 需要在程式中如何啟用？ \n 使用時需先在場景中的機器人裝上 Camera 裝置，接著在程式中啟用它。 \n', 'tags': '', 'url': 'Tutorial6 相關提問:.html'}, {'title': 'Python 範例：', 'text': "\n python \n \n \n \n camera = robot.getDevice('camera') camera.enable(timestep) # 啟用攝影機並設定更新頻率 \n \n \n \n \n \n \n 三、 如何取得攝影機擷取到的影像資料？ \n 可使用下列方法取得像素資料（為 raw bytes 格式）： \n \n python \n \n \n \n image = camera.getImage() width = camera.getWidth() height = camera.getHeight() \n \n \n \n 你可以使用 Webots 的圖像處理 API，例如： \n \n python \n \n \n \n r = Camera.imageGetRed(image, width, x, y) g = Camera.imageGetGreen(image, width, x, y) b = Camera.imageGetBlue(image, width, x, y) \n \n \n \n \n \n \n 四、 Tutorial6 中，機器人如何依據攝影機影像做出反應？ \n 在 Tutorial6，機器人會： \n \n \n 使用攝影機偵測畫面中是否出現  特定顏色的物體 \n \n \n 透過簡單的像素分析，若偵測到某顏色，就執行動作（例如轉向、停止） \n \n \n", 'tags': '', 'url': 'Python 範例：.html'}, {'title': '例：', 'text': '如果畫面中心的像素呈紅色，則機器人轉向紅色物體。 \n \n 五、 Camera 裝置可以調整哪些參數？ \n 可在機器人設定中調整以下參數： \n \n \n \n \n \n 參數名稱 \n 功能 \n \n \n \n \n width ,  height \n 攝影機解析度 \n \n \n fieldOfView \n 視野角度（FOV） \n \n \n near ,  far \n 近 / 遠裁剪面（剪除畫面以外區域） \n \n \n motionBlur \n 是否模擬動態模糊 \n \n \n antiAliasing \n 抗鋸齒處理（改善畫質） \n \n \n \n \n \n \n 六、 影像解析度的設定會對模擬有什麼影響？ \n \n \n \n \n \n 解析度高 \n 解析度低 \n \n \n \n \n 更清晰、細節更多 \n 畫質粗糙 \n \n \n 影像處理更準確 \n 難以辨識小物體 \n \n \n 會 增加計算量與模擬延遲 \n 效能較佳，適合快速模擬 \n \n \n \n \n \n 建議依照應用需求（例如只辨認顏色不需高解析）選擇合適解析度。 \n \n 七、 如何將攝影機影像儲存成圖片檔？ \n 可使用 Webots 提供的方法： \n \n python \n \n \n \n camera.saveImage("image.png", quality) \n \n \n \n \n \n \n quality ：介於 1 到 100，代表影像壓縮品質。 \n \n \n 完整例子： \n \n python \n \n camera.saveImage("snapshot.png", 100) \n \n camera.saveImage( "snapshot.png" ,  100 )  \n \n 也可結合 OpenCV 寫入圖片： \n \n python \n \n \n \n import numpy as np import cv2 image = camera.getImage() width = camera.getWidth() height = camera.getHeight() img_array = np.frombuffer(image, np.uint8).reshape((height, width, 4)) bgr_image = cv2.cvtColor(img_array, cv2.COLOR_BGRA2BGR) cv2.imwrite("snapshot_cv.png", bgr_image) \n \n \n \n \n \n 八、 若攝影機影像顯示異常，可能的原因有哪些？ \n \n \n \n \n \n 問題情形 \n 可能原因 \n \n \n \n \n 畫面為黑（全 0 值） \n 沒有  enable()  或 timestep 設為 0 \n \n \n 畫面畫質太差或閃爍 \n 解析度太低 / 頻率過低 / 模擬效能不足 \n \n \n 顏色異常（如全綠） \n RGB 通道讀取錯誤，需確認  imageGetRed()  等使用正確 \n \n \n 儲存圖片為空檔 \n saveImage()  檔名路徑錯誤或沒寫入權限 \n \n \n 調用 OpenCV 時轉換錯誤 \n 需先轉換成 NumPy 格式、注意通道順序與格式 \n \n \n \n \n \n \n \n \n \n', 'tags': '', 'url': '例：.html'}, {'title': '✅ 總結：攝影機應用流程建議', 'text': '\n \n 在  .wbt  中確認已為機器人加入 Camera 裝置 \n \n \n 在控制器中啟用 Camera： camera.enable(timestep) \n \n \n 透過  camera.getImage()  取得畫面 \n \n \n 使用 Webots API 或 OpenCV 處理影像 \n \n \n 設定合理的解析度與更新頻率 \n \n \n 可根據顏色或特徵設計機器人反應邏輯 \n \n \n', 'tags': '', 'url': '✅ 總結：攝影機應用流程建議.html'}, {'title': 'Midterm', 'text': '本課程所繳交的期中成績為學員自評之學習期望成績. \n 期中考週的自評期望成績繳交流程: \n \n 整理先前所完成的各週的進度、作業網頁內容以及心得 \n 拍攝期中自評影片, 上傳至 Youtube 後, 以" 國立虎尾科技大學 - 機械設計工程系 - cd2025 期中自評- 學員學號 "為影片標題後嵌入本頁面中 \n 回填期中自評表單 \n 上傳學員期中成績 \n \n 各週進度: \n 各週網頁內容: \n 期中心得: \n 期中自評影片: \n \n \n', 'tags': '', 'url': 'Midterm.html'}, {'title': '期中表單', 'text': '41223116 吳長逸 \n 請在以下欄位列出您的課程作業倉儲網址 \n https://github.com/mdecd2025/hw-41223116 \n 請在以下欄位列出您的課程作業 Github Pages 網址 \n https://mdecd2025.github.io/hw-41223116/ \n 請在以下欄位填入您的課程作業倉儲提交 (commits) 總數 \n 5 \n 請根據課程內容的要求, 在以下欄位填入您自我評量後的課程學期期望成績 \n 65 \n \n 請在以下欄位詳細說明您上課至今所遭遇問題以及心得 \n \n 雖然會畫圖，但是這堂課的網路倉儲和物理模擬我需要速度再慢點的教學，我跟不上目前的教學速度，可能其他人可以理解做這個或者這串語言，但是我希望教學是一個小段落停留讓我先跟上，現在的教學我離大家的進度越來越遠，跟上的動力越來越小了 現在畫圖變快了，打字也熟練了，有最基本的能力，也大概知道在做甚麼，但是不會做或者不知道這段城市在做甚麼是我目前最大的問題。 \n \n 5/9 \n webots基本操作會了，現在對link的概念有點模糊，只知道他是組件一參考組件二位置。然後建立 solid只知道他是作為剛體使用，不知道它建立在這個位置作用是甚麼。 \n \n', 'tags': '', 'url': '期中表單.html'}, {'title': 'Exam', 'text': 'Exam1 (10%): 建立 Webots 基本物件模擬場景 \n 各學員利用 Webots R2025a 套件中的 Shape 物件, 隨堂建立指定的機電系統模擬場景, 並利用 Python 程式進行互動控制. \n Exam2 (10%): 利用 CAD 零組件建立模擬場景\xa0 \n 各學員利用 CAD (Solvespace 與 NX2312), 隨堂建立指定的系統模型零組件後, 導入 Webots R2025a 後, 建立機電系統模擬場景, 並利用 Python 程式進行互動控制. \n Exam3 (20%): Webots 機電模擬場景的協同設計 \n 各分組利用 CAD (Solvespace 與 NX2312), 隨堂建立指定的系統模型零組件後, 導入 Webots R2025a 後, 建立機電系統模擬場景, 並利用 Python 程式進行互動控制. 過程中各學員必須採同步協同模式, 維護從 Github Classroom 取得的分組協同倉儲以及網站. \n 協同分組方式: \n \n 分配學員負責利用 Solvespace 建立系統零組件, 過程中必須將所建構之零組件檔案與繪圖過程影片上傳至分組網頁. \n 分配學員負責利用 NX2312 建立系統零組件, 過程中必須將所建構之零組件檔案與繪圖過程影片上傳至分組網頁. \n 分配學員負責利用 Webots 建立機電系統模擬場景, 並利用 Python 程式進行控制, 過程中必須將建構過程拍成帶有說明字幕的影片上傳至分組網頁. \n \n', 'tags': '', 'url': 'Exam.html'}, {'title': 'Exam前置', 'text': '\n \n /downloads/fourbar_slvs.7z \n', 'tags': '', 'url': 'Exam前置.html'}, {'title': 'Exam1', 'text': 'Exsm1 webots檔案 /downloads/w4.1.7z \n Exam1 (10%): 建立 Webots 基本物件模擬場景 \n 操作影片標題: 國立虎尾科技大學 - 機械設計工程系 - cd2025 Exam1 - 41223116 \n \n', 'tags': '', 'url': 'Exam1.html'}, {'title': 'Exam2', 'text': 'Exam2 (10%): 利用 CAD 零組件建立模擬場景 \n 檔案: /downloads/55.zip \n 操作影片標題: 國立虎尾科技大學 - 機械設計工程系 - cd2025 Exam2 - 學員學號 \n \n \n /downloads/41223116_EXAM2.zip \n \n', 'tags': '', 'url': 'Exam2.html'}, {'title': 'Exam3', 'text': 'Exam3 (20%): Webots 機電模擬場景的協同設計 \n 操作影片標題: 國立虎尾科技大學 - 機械設計工程系 - cd2025 Exam3 - 學員學號 \n', 'tags': '', 'url': 'Exam3.html'}, {'title': 'Final', 'text': '期末協同專案執行過程影片、簡報與 PDf 報告檔案 (六人一組) (30%) \n 題目:  Webots 動態投籃模擬系統的協同設計 \n 說明:  \n 籃框架被配置在一定範圍內, 可隨機慢速前進、後退及左右擺動, 投籃機構系統帶有一定數量的籃球, 被配置在可自由移動的輪車上. \n 操作者可利用鍵盤特定按鍵控制投籃輪車的移動並發射投籃, 每投出一球後系統透過記分板進行計分, 並由送球機構進行補球或移動輪車取球, 遊戲可進行至全部數量籃球投完為止. \n 請將期末協同專案執行過程、內容與心得, 製作成影片，配合字幕上傳至 Youtube 後嵌入各階段的期末報告頁面中. \n 影片標題:  國立虎尾科技大學 - 機械設計工程系 - cd2025 期末報告 - 學員學號 - 各階段影片主題 \n', 'tags': '', 'url': 'Final.html'}, {'title': 'Brython', 'text': '1 add to 100 \n  導入 brython 程式庫  \n \n \n \n \n  啟動 Brython  \n \n \n \n  導入 FileSaver 與 filereader  \n \n \n \n \n  導入 ace  \n \n \n \n \n \n \n  導入 gearUtils-0.9.js Cango 齒輪繪圖程式庫  \n \n \n \n \n \n \n  請注意, 這裡使用 Javascript 將 localStorage["kw_py_src1"] 中存在近端瀏覽器的程式碼, 由使用者決定存檔名稱 \n \n \n \n \n \n \n  add 1 to 100 開始  \n \n \n  add 1 to 100 結束 \n  editor1 開始  \n  用來顯示程式碼的 editor 區域  \n \n  以下的表單與按鈕與前面的 Javascript doSave 函式以及 FileSaver.min.js 互相配合  \n  存擋表單開始  \n Filename:  .py   \n  存擋表單結束  \n \n  執行與清除按鈕開始  \n Run   Output   清除輸出區 清除繪圖區 Reload \n  執行與清除按鈕結束  \n \n  程式執行 ouput 區  \n \n  Brython 程式執行的結果, 都以 brython_div1 作為切入位置  \n \n  editor1 結束   ##########################################  \n 從 1 累加到 100 part2: \n 1 add to 100 cango_three_gears BSnake AI Tetris \n  請注意, 這裡使用 Javascript 將 localStorage["kw_py_src2"] 中存在近端瀏覽器的程式碼, 由使用者決定存檔名稱 \n \n \n \n  add 1 to 100 part2 開始  \n \n \n  add 1 to 100 part2 結束 \n  editor2 開始  \n  用來顯示程式碼的 editor 區域  \n \n  以下的表單與按鈕與前面的 Javascript doSave 函式以及 FileSaver.min.js 互相配合  \n  存擋表單開始  \n Filename:  .py   \n  存擋表單結束  \n \n  執行與清除按鈕開始  \n Run   Output   清除輸出區 清除繪圖區 Reload \n  執行與清除按鈕結束  \n \n  程式執行 ouput 區  \n \n  Brython 程式執行的結果, 都以 brython_div1 作為切入位置  \n \n  editor2 結束  \n \n \n', 'tags': '', 'url': 'Brython.html'}]};